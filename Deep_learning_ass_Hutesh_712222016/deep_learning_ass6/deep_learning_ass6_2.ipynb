{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "YAGav7XbCoww",
        "outputId": "2cea5d2f-f38d-430f-a7a0-1a453a356ef8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1eb00ff78cf2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "# Define the function to optimize (2D Rosenbrock function)\n",
        "def rosenbrock(x, y):\n",
        "    return (1 - x)**2 + 100 * (y - x**2)**2\n",
        "\n",
        "# Define the optimization algorithms\n",
        "optimizers = ['gd', 'momentum', 'nag', 'adagrad', 'rmsprop', 'adam']\n",
        "\n",
        "# Define the animation update function\n",
        "def update(frame):\n",
        "    ax.cla()\n",
        "    optimizer = optimizers[frame]\n",
        "    ax.set_title(optimizer.upper() + \" Optimization\")\n",
        "\n",
        "    # Perform optimization\n",
        "    x = np.linspace(-2, 2, 100)\n",
        "    y = np.linspace(-1, 3, 100)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = rosenbrock(X, Y)\n",
        "\n",
        "    # Plot the contour\n",
        "    ax.contour(X, Y, Z, levels=np.logspace(-1, 3, 10))\n",
        "\n",
        "    # Initialize parameters\n",
        "    curr_x, curr_y = -2, 2\n",
        "    prev_dx, prev_dy = 0, 0\n",
        "\n",
        "    # Perform optimization iterations\n",
        "    iterations = 100\n",
        "    learning_rate = 0.001\n",
        "    for i in range(iterations):\n",
        "        # Compute gradients\n",
        "        dx = 2 * (200 * curr_x**3 - 200 * curr_x * curr_y + curr_x - 1)\n",
        "        dy = 200 * (curr_y - curr_x**2)\n",
        "\n",
        "        # Update parameters based on the optimizer\n",
        "        if optimizer == 'gd':  # Gradient Descent\n",
        "            curr_x -= learning_rate * dx\n",
        "            curr_y -= learning_rate * dy\n",
        "        elif optimizer == 'momentum':  # Momentum\n",
        "            curr_x, curr_y, prev_dx, prev_dy = (\n",
        "                curr_x - learning_rate * dx + 0.9 * prev_dx,\n",
        "                curr_y - learning_rate * dy + 0.9 * prev_dy,\n",
        "                dx, dy\n",
        "            )\n",
        "        elif optimizer == 'nag':  # Nesterov Accelerated Gradient\n",
        "            lookahead_x, lookahead_y = (\n",
        "                curr_x - learning_rate * 0.9 * prev_dx,\n",
        "                curr_y - learning_rate * 0.9 * prev_dy\n",
        "            )\n",
        "            lookahead_dx = 2 * (200 * lookahead_x**3 - 200 * lookahead_x * lookahead_y + lookahead_x - 1)\n",
        "            lookahead_dy = 200 * (lookahead_y - lookahead_x**2)\n",
        "            curr_x, curr_y, prev_dx, prev_dy = (\n",
        "                curr_x - learning_rate * dx + 0.9 * lookahead_dx,\n",
        "                curr_y - learning_rate * dy + 0.9 * lookahead_dy,\n",
        "                lookahead_dx, lookahead_dy\n",
        "            )\n",
        "        elif optimizer == 'adagrad':  # AdaGrad\n",
        "            cache_x += dx**2\n",
        "            cache_y += dy**2\n",
        "            curr_x -= learning_rate * dx / np.sqrt(cache_x + 1e-8)\n",
        "            curr_y -= learning_rate * dy / np.sqrt(cache_y + 1e-8)\n",
        "        elif optimizer == 'rmsprop':  # RMSProp\n",
        "            cache_x = 0.9 * cache_x + 0.1 * dx**2\n",
        "            cache_y = 0.9 * cache_y + 0.1 * dy**2\n",
        "            curr_x -= learning_rate * dx / np.sqrt(cache_x + 1e-8)\n",
        "            curr_y -= learning_rate * dy / np.sqrt(cache_y + 1e-8)\n",
        "        elif optimizer == 'adam':  # Adam\n",
        "            m_x = 0.9 * m_x + 0.1 * dx\n",
        "            m_y = 0.9 * m_y + 0.1 * dy\n",
        "            v_x = 0.999 * v_x + 0.001 * dx**2\n",
        "            v_y = 0.999 * v_y + 0.001 * dy**2\n",
        "            m_x_hat = m_x / (1 - 0.9**(i + 1))\n",
        "            m_y_hat = m_y / (1 - 0.9**(i + 1))\n",
        "            v_x_hat = v_x / (1 - 0.999**(i + 1))\n",
        "            v_y_hat = v_y / (1 - 0.999**(i + 1))\n",
        "            curr_x -= learning_rate * m_x_hat / (np.sqrt(v_x_hat) + 1e-8)\n",
        "            curr_y -= learning_rate * m_y_hat / (np.sqrt(v_y_hat) + 1e-8)\n",
        "\n",
        "        # Plot the current point\n",
        "        ax.plot(curr_x, curr_y, 'bo')\n",
        "\n",
        "    return ax\n",
        "\n",
        "# Create the figure and axis\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(xlim=(-2, 2), ylim=(-1, 3))\n",
        "\n",
        "# Create the animation\n",
        "anim = animation.FuncAnimation(fig, update, frames=len(optimizers), interval=1000, repeat=True)\n",
        "\n",
        "# Display the animation\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2d5RHpzzDC53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}